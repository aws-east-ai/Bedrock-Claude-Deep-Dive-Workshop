{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac39f28-e48a-4970-9efd-7aaaacf68037",
   "metadata": {},
   "source": [
    "# Multimodal RAG using Bedrock Titan and Claude3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2630bb6-847f-47b2-8ec5-e9cd04df338f",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce01b87-ba55-4e4b-9d77-41e6cd80fc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get update -y\n",
    "!sudo apt -y install poppler-utils tesseract-ocr\n",
    "!sudo apt install ffmpeg libsm6 libxext6  -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07467d0b-e25c-45f8-84c8-9776c7239907",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pdf2image\n",
    "!pip install -U pytesseract\n",
    "!pip install -U langchain langchain-experimental langchain-aws\n",
    "!pip install -U unstructured[all-docs] pillow pydantic lxml pillow matplotlib tiktoken open_clip_torch torch\n",
    "!pip install -U faiss-cpu tiktoken\n",
    "!pip install -U nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e294c38-5b73-4db5-adfc-5a0463edb18b",
   "metadata": {},
   "source": [
    "## Download and process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec94b47-f2d9-45e2-bffe-35b06de504a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "!wget \"https://www.getty.edu/publications/resources/virtuallibrary/0892360224.pdf\" --no-check-certificate\n",
    "shutil.move(\"0892360224.pdf\",\"input.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e420bb7a-1ac5-4c94-a436-6529cef0ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"figures\"\n",
    "# file_name = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71643ca8-d14c-4e60-a370-3bbcf1c2037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract images, tables, and chunk text\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "raw_pdf_elements = partition_pdf(\n",
    "    filename='input.pdf',\n",
    "    extract_images_in_pdf=True,\n",
    "    infer_table_structure=True,\n",
    "    chunking_strategy=\"by_title\",\n",
    "    max_characters=4000,\n",
    "    new_after_n_chars=3800,\n",
    "    combine_text_under_n_chars=2000,\n",
    "    image_output_dir_path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffb3ea0-7109-45e8-882e-d7ba9d928e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = []\n",
    "texts = []\n",
    "for element in raw_pdf_elements:\n",
    "    if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "        tables.append(str(element))\n",
    "    elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "        texts.append(str(element))\n",
    "#\n",
    "print(len(tables))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.open(\"figures/figure-26-29.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6702d3-e739-4004-8716-e5cdcf37f83f",
   "metadata": {},
   "source": [
    "## Import texts and images embedding to Faiss vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9248da77-3ab8-466c-b241-ae20c36fbca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the quality of texts\n",
    "texts = [text for text in texts if len(text) > 20]\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c59f2a-9e2f-4dd3-9ba6-30ad798b1762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image URIs with .jpg extension only\n",
    "image_uris = sorted(\n",
    "    [\n",
    "        os.path.join(path, image_name)\n",
    "        for image_name in os.listdir(path)\n",
    "        if image_name.endswith(\".jpg\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b148454b-43dc-4f81-bd11-235e44ce2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client(\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79457d5f-f3a1-434e-8910-41f8ab4f95c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "\n",
    "def base64_encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf8')\n",
    "\n",
    "def generate_embeddings(image_base64=None, text_description=None):\n",
    "    input_data = {}\n",
    "\n",
    "    if image_base64 is not None:\n",
    "        input_data[\"inputImage\"] = image_base64\n",
    "    if text_description is not None:\n",
    "        input_data[\"inputText\"] = text_description\n",
    "\n",
    "    if not input_data:\n",
    "        raise ValueError(\"At least one of image_base64 or text_description must be provided\")\n",
    "\n",
    "    body = json.dumps(input_data)\n",
    "\n",
    "    response = client.invoke_model(\n",
    "        body=body,\n",
    "        modelId=\"amazon.titan-embed-image-v1\",\n",
    "        accept=\"application/json\",\n",
    "        contentType=\"application/json\"\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "    finish_reason = response_body.get(\"message\")\n",
    "\n",
    "    if finish_reason is not None:\n",
    "        raise EmbedError(f\"Embeddings generation error: {finish_reason}\")\n",
    "\n",
    "    return response_body.get(\"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f239f3c-6fff-4464-9479-5ffdc657b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate images embedding using Titan multimodal embedding\n",
    "images_embeddings = []\n",
    "for image in image_uris:\n",
    "    embedding = (image, generate_embeddings(image_base64=base64_encode_image(image)))\n",
    "    images_embeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ab1104-7979-44b6-9322-baf439b96e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "import numpy as np\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from PIL import Image as _PILImage\n",
    "\n",
    "\n",
    "embeddings = BedrockEmbeddings(client=client, model_id='amazon.titan-embed-image-v1')\n",
    "\n",
    "# Create Faiss vector store\n",
    "vectorstore = FAISS.from_texts(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4962754-bb70-43ef-b2cc-88c3697e0fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print vectors dimension and vector counts before add images embedding\n",
    "dimension = vectorstore.index.d\n",
    "print(f\"Dimension of vectors in the index: {dimension}\")\n",
    "print(\"Vector counts:\", vectorstore.index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c961000d-b91e-4aae-bfb0-614786f3ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add images embedding\n",
    "vectorstore.add_embeddings(images_embeddings)\n",
    "\n",
    "print(\"Vector counts:\", vectorstore.index.ntotal)\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9658daec-6b96-455c-a03c-c45da6a4f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Delete vectors\n",
    "print(\"count before:\", vectorstore.index.ntotal)\n",
    "\n",
    "for i in range(34):\n",
    "    vectorstore.delete([vectorstore.index_to_docstore_id[i]])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909d743b-d132-4f7d-bc41-1242a73fe057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try similartiy search between text and images\n",
    "docs_and_scores = vectorstore.similarity_search_with_score(\"Moses and the Messengers from Canaan\")\n",
    "docs_and_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d868b5-17be-4cb0-9c3a-9807f103a2c9",
   "metadata": {},
   "source": [
    "## Build Multimodal RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f22dc7-2d87-4035-bade-2a1650627784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def resize_base64_image(image_path, size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Resize an image encoded as a Base64 string.\n",
    "\n",
    "    Args:\n",
    "    base64_string (str): Base64 string of the original image.\n",
    "    size (tuple): Desired size of the image as (width, height).\n",
    "\n",
    "    Returns:\n",
    "    str: Base64 string of the resized image.\n",
    "    \"\"\"\n",
    "    # Decode the Base64 string\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = img.resize(size, Image.LANCZOS)\n",
    "\n",
    "    # Save the resized image to a bytes buffer\n",
    "    buffered = io.BytesIO()\n",
    "    resized_img.save(buffered, format=img.format)\n",
    "\n",
    "    # Encode the resized image to Base64\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def is_image(s):\n",
    "    \"\"\"Check if a string is Base64 encoded\"\"\"\n",
    "    try:\n",
    "        return s.endswith(\".jpg\") \n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def split_image_text_types(docs):\n",
    "    \"\"\"Split numpy array images and texts\"\"\"\n",
    "    images = []\n",
    "    text = []\n",
    "    for doc in docs:\n",
    "        doc = doc.page_content  # Extract Document contents\n",
    "        if is_image(doc):\n",
    "            # Resize image to avoid OAI server error\n",
    "            images.append(\n",
    "                resize_base64_image(doc, size=(250, 250))\n",
    "            )  # base64 encoded str\n",
    "        else:\n",
    "            text.append(doc)\n",
    "    return {\"images\": images, \"texts\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77db3cb-0ab7-4c55-b89e-59b313d21982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough,RunnableParallel\n",
    "\n",
    "\n",
    "def prompt_func(data_dict):\n",
    "    # Joining the context texts into a single string\n",
    "    formatted_texts = \"\\n\".join(data_dict[\"context\"][\"texts\"])\n",
    "    messages = []\n",
    "\n",
    "    # Adding image(s) to the messages if present\n",
    "    if data_dict[\"context\"][\"images\"]:\n",
    "        image_message = {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{data_dict['context']['images'][0]}\"\n",
    "            },\n",
    "        }\n",
    "        messages.append(image_message)\n",
    "\n",
    "    # Adding the text message for analysis\n",
    "    text_message = {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": (\n",
    "            \"As an expert art critic and historian, your task is to analyze and interpret images, \"\n",
    "            \"considering their historical and cultural significance. Alongside the images, you will be \"\n",
    "            \"provided with related text to offer context. Both will be retrieved from a vectorstore based \"\n",
    "            \"on user-input keywords. Please use your extensive knowledge and analytical skills to provide a \"\n",
    "            \"comprehensive summary that includes:\\n\"\n",
    "            \"- A detailed description of the visual elements in the image.\\n\"\n",
    "            \"- The historical and cultural context of the image.\\n\"\n",
    "            \"- An interpretation of the image's symbolism and meaning.\\n\"\n",
    "            \"- Connections between the image and the related text.\\n\\n\"\n",
    "            f\"User-provided keywords: {data_dict['question']}\\n\\n\"\n",
    "            \"Text and / or tables:\\n\"\n",
    "            f\"{formatted_texts}\"\n",
    "        ),\n",
    "    }\n",
    "    messages.append(text_message)\n",
    "\n",
    "    return [HumanMessage(content=messages)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aabfae-f9f1-4b88-8ab2-3198203ebacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def plt_img_base64(img_base64):\n",
    "    # Create an HTML img tag with the base64 string as the source\n",
    "    image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
    "\n",
    "    # Display the image by rendering the HTML\n",
    "    display(HTML(image_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562c257c-6be5-4f39-b038-15ea79d4f822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "# Using Bedrock Claude3\n",
    "model = ChatBedrock(\n",
    "    client=client,\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    model_kwargs={\"temperature\": 0.1, \"max_tokens\": 1024},\n",
    ")\n",
    "\n",
    "# RAG pipeline\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever | RunnableLambda(split_image_text_types),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | RunnableParallel({\"response\":prompt_func| model| StrOutputParser(),\n",
    "                      \"context\": itemgetter(\"context\"),})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6078a70-6a36-4bff-876f-67a317967d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve related images and texts then invoke Claude3 to generate answer\n",
    "response = chain.invoke(\"Madonna and Child with Two Saints and a Donor\")\n",
    "print(response['response'])\n",
    "plt_img_base64(response['context']['images'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f794376e-18bd-4cb3-875e-841c6925ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check context\n",
    "print(response['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dff6449-aae2-434b-94aa-aab839517ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
